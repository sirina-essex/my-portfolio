<!DOCTYPE HTML>
<html>

<head>
	<title>Collaborative discussion 2: Accuracy of information</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
	<style>
		blockquote {
			white-space: normal;
			word-wrap: break-word;
		}

		.columns {
			display: flex;
			justify-content: space-between;
			gap: 20px;
		}

		.column {
			width: 48%;
		}

		.box {
			border: 1px solid #ddd;
			padding: 15px;
		}
	</style>
</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header" class="alt style2">
			<a href="index.html" class="logo"><strong>IRINA Stephanie</strong> <span>Collaborative discussion
					2</span></a>
			<nav>
				<a href="#menu">Menu</a>
			</nav>
		</header>

		<!-- Menu -->
		<nav id="menu">
			<ul class="links">
				<li><a href="index.html">Home</a></li>
				<li><a href="about.html">About Me</a></li>
				<li><a href="artefact.html">List of Artefacts</a></li>
				<li><a href="reflection.html">Reflections</a></li>

			</ul>
		</nav>


		<!-- Main -->
		<div id="main" class="alt">

			<!-- Case Study Section -->
			<section id="one">
				<div class="inner">
					<header class="major">
						<h1>Contributions to Peer Work</h1>
					</header>
					<p>This page highlights my key contributions to peer work throughout the Collaborative disussion 2
						about " Accuracy of information", where I provided
						feedback.</p>

					<!-- Context Blockquote -->
					<section id="peer-contributions">
						<div class="inner">


							<!-- First Contribution -->
							<div class="box">
								<h2>Contribution to Noora Alboinin's Post on the case study</h2>
								<p><strong>Peer response by Stephanie Irina - Monday, 16 June 2025, 9:43 PM</strong>
								</p>
								<blockquote>
									<p>The contribution accurately highlights fundamental issues related to ethical responsibility in the presentation of statistical results, notably the importance of transparency, integrity, and the duty to raise concerns when public risk is involved. These elements align with the expectations outlined in professional codes of conduct that govern scientific and analytical practice (National Academies of Sciences, 2017).</p>
                                    <p> Two complementary dimensions further deepen this ethical analysis: methodological traceability and the clarification of professional boundaries within the broader chain of responsibility.</p>
                                    <p>First, methodological traceability ensures that all analytical decisions (from variable selection to the application of statistical treatments) are rigorously documented and verifiable by third parties. Gelman and Loken (2014) argue that the absence of clear documentation constitutes a direct threat to scientific integrity, as it undermines both transparency and reproducibility. In Abi’s case, this means that beyond presenting final results, he is ethically required to disclose the methodological steps that led to those results, enabling a comprehensive and honest assessment of his analytical work.</p>
                                    <p>Second, it is essential to delineate roles and responsibilities in collaborative projects involving sensitive or publicly impactful data. Steneck (2006) reminds us that researchers and analysts are accountable for the quality, clarity, and interpretability of their work, but not for the ultimate use of that work by other actors such as communicators, marketers, or regulatory authorities. From this perspective, Abi must act with rigour, raise concerns when misuse is foreseeable, and document his process thoroughly, yet he should not be held responsible for decisions beyond his functional scope.</p>
                                    <p>In this context, professional ethics go beyond statistical accuracy or individual intent. They demand procedural transparency and a clear distribution of responsibility within institutions. Vigilance cannot rest on a single actor; it must be shared and structured through common frameworks. Macrina (2014) further emphasises the need for explicit, institutionalised ethical structures that support coherent coordination among all parties involved.</p>
									<p><strong>References:</strong><br>
										Gelman, A. and Loken, E. (2014) ‘The Statistical Crisis in Science’, American Scientist, 102(6). Available at: https://www.americanscientist.org/article/the-statistical-crisis-in-science (Accessed: 16 June 2025)<br>
										Macrina, F.L. (2014) Scientific integrity: Text and cases in responsible conduct of research. 4th edn. Washington, DC: ASM Press.<br>
										National Academies of Sciences, Engineering, and Medicine (2017) Fostering Integrity in Research. The National Academies Press. Available at: https://nap.nationalacademies.org/catalog/21896/fostering-integrity-in-research  https://nap.nationalacademies.org/catalog/21896/fostering-integrity-in-research (Accessed: 15 June 2025)<br>
										Steneck, N.H. (2006) ‘Fostering integrity in research: Definitions, current knowledge, and future directions’, Science and Engineering Ethics, 12(1), pp. 53–74. Available at: https://www.researchgate.net/publication/7275253_Fostering_Integrity_in_Research_Definitions_Current_Knowledge_and_Future_Directions (Accessed: 16 June 2025)</p>
								</blockquote>
							</div>

							<!-- Second Contribution -->
							<div class="box">
								<h2>Contribution to Rodrigo Pereira Cruz's Post: Death Machines - The Ethics of Autonomous Weapons</h2>
								<p><strong>Peer response by Stephanie Irina - Friday, 2 May 2025, 7:36 PM</strong>
								</p>
								<blockquote>
									<p>The issue of lethal autonomous weapon systems (LAWS) indeed raises numerous ethical and political challenges. Beyond the legitimate criticism of observed abuses, it is also useful to consider that certain tightly regulated uses of these technologies could help reduce human casualties, for example by lowering the exposure of soldiers or by integrating automatic deactivation mechanisms in the presence of civilians. This suggests that the real problem often lies less in the technology itself than in the lack of clear governance, decision-making transparency, and shared accountability mechanisms.</p>
									<p>Another major concern is the risk of dehumanising decision-making. Delegating lethal decision-making power to an algorithm raises a fundamental question: who is responsible in the event of an error or misuse? This dilution of moral and legal judgement can lead to a form of systemic irresponsibility, as thoroughly examined by Malik (2017). In response to this issue, Verdiesen, Santoni de Sio, and Dignum (2021) propose a governance framework based on distributed human responsibility, which clearly assigns roles throughout the system’s lifecycle—from design to operational deployment. This approach encourages ethical oversight and helps reduce decision-making grey areas.</p>
									<p>Similarly, Amoroso and Tamburrini (2021) provide a legal and ethical definition of what constitutes “meaningful human control” in a framework aligned with international humanitarian law. According to them, such control not only requires human presence in the decision-making loop, but also a real ability to understand, anticipate, and interrupt system behaviour, even in complex operational environments. This reinforces the idea that autonomy must never become a way to escape responsibility, and that human supervision remains essential to ensure the ethical and legal compliance of lethal decisions.</p>
									<p><strong>References:</strong><br>
										Amoroso, D. and Tamburrini, 2021. Toward a normative model of meaningful human control over weapons systems. Ethics & International Affairs, Available at: https://www.cambridge.org/core/services/aop-cambridge-core/content/view/A3FD9EC4CBD6EA77439211537B94A444/S0892679421000241a.pdf [Accessed 6 May 2025].<br>
										Malik, S., 2017. Autonomous weapon systems: The possibility and probability of accountability. Wisconsin International Law Journal, Available at: https://wilj.law.wisc.edu/wp-content/uploads/sites/1270/2018/10/Malik_Final.pdf [Accessed 7 May 2025].<br>
										    Verdiesen, Santoni de Sio, and Dignum, 2021. Accountability and control over autonomous weapon systems: A framework for comprehensive human oversight. Minds and Machines, Available at: https://link.springer.com/content/pdf/10.1007/s11023-020-09532-9.pdf [Accessed 6 May 2025].</p>
								</blockquote>
							</div>


						</div>
					</section>


				</div>
			</section>
		</div>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>